{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af112e1",
   "metadata": {},
   "source": [
    "1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.<br>\n",
    "●\tИгнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.<br>\n",
    "●\tОграничим количество слов, попадающий в мешок, с помощью max_features = 1000.<br>\n",
    "●\tИсключим стоп-слова с помощью stop_words='english'.<br>\n",
    "●\tОтобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4149d4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when fatheare is dysfyounctional and is so sel...</td>\n",
       "      <td>[\"when\", \"fatheare\", \"is\", \"dysfyounctional\", ...</td>\n",
       "      <td>[\"fatheare\", \"dysfyounctional\", \"selfish\", \"da...</td>\n",
       "      <td>[\"fathear\", \"dysfyounct\", \"selfish\", \"dareagar...</td>\n",
       "      <td>[\"fatheare\", \"dysfyounctional\", \"selfish\", \"da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks foare lyft careedit cannot youse cayous...</td>\n",
       "      <td>[\"thanks\", \"foare\", \"lyft\", \"careedit\", \"can\",...</td>\n",
       "      <td>[\"thanks\", \"foare\", \"lyft\", \"careedit\", \"youse...</td>\n",
       "      <td>[\"thank\", \"foar\", \"lyft\", \"careedit\", \"yous\", ...</td>\n",
       "      <td>[\"thank\", \"foare\", \"lyft\", \"careedit\", \"youse\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday yoyouare majesty</td>\n",
       "      <td>[\"bihday\", \"yoyouare\", \"majesty\"]</td>\n",
       "      <td>[\"bihday\", \"yoyouare\", \"majesty\"]</td>\n",
       "      <td>[\"bihday\", \"yoyouar\", \"majesti\"]</td>\n",
       "      <td>[\"bihday\", \"yoyouare\", \"majesty\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in y...</td>\n",
       "      <td>[\"model\", \"love\", \"you\", \"take\", \"with\", \"you\"...</td>\n",
       "      <td>[\"model\", \"love\", \"take\", \"time\", \"youare\"]</td>\n",
       "      <td>[\"model\", \"love\", \"take\", \"time\", \"youar\"]</td>\n",
       "      <td>[\"model\", \"love\", \"take\", \"time\", \"youare\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsgareinyouide society now motivation</td>\n",
       "      <td>[\"factsgareinyouide\", \"society\", \"now\", \"motiv...</td>\n",
       "      <td>[\"factsgareinyouide\", \"society\", \"motivation\"]</td>\n",
       "      <td>[\"factsgareinyouid\", \"societi\", \"motiv\"]</td>\n",
       "      <td>[\"factsgareinyouide\", \"society\", \"motivation\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thoyougareinht factoarey left areigareinht pol...</td>\n",
       "      <td>[\"thoyougareinht\", \"factoarey\", \"left\", \"areig...</td>\n",
       "      <td>[\"thoyougareinht\", \"factoarey\", \"left\", \"areig...</td>\n",
       "      <td>[\"thoyougareinht\", \"factoarey\", \"left\", \"areig...</td>\n",
       "      <td>[\"thoyougareinht\", \"factoarey\", \"leave\", \"arei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feelingarein like mearemaid haiareflip neveare...</td>\n",
       "      <td>[\"feelingarein\", \"like\", \"mearemaid\", \"haiaref...</td>\n",
       "      <td>[\"feelingarein\", \"like\", \"mearemaid\", \"haiaref...</td>\n",
       "      <td>[\"feelingarein\", \"like\", \"mearemaid\", \"haiaref...</td>\n",
       "      <td>[\"feelingarein\", \"like\", \"mearemaid\", \"haiaref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>hillaarey campaigareinned today in ohio oh my ...</td>\n",
       "      <td>[\"hillaarey\", \"campaigareinned\", \"today\", \"in\"...</td>\n",
       "      <td>[\"hillaarey\", \"campaigareinned\", \"today\", \"ohi...</td>\n",
       "      <td>[\"hillaarey\", \"campaigarein\", \"today\", \"ohio\",...</td>\n",
       "      <td>[\"hillaarey\", \"campaigareinned\", \"today\", \"ohi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy at woarek confeareence areigareinht mind...</td>\n",
       "      <td>[\"happy\", \"at\", \"woarek\", \"confeareence\", \"are...</td>\n",
       "      <td>[\"happy\", \"woarek\", \"confeareence\", \"areigarei...</td>\n",
       "      <td>[\"happi\", \"woarek\", \"confear\", \"areigareinht\",...</td>\n",
       "      <td>[\"happy\", \"woarek\", \"confeareence\", \"areigarei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my songarein so gareinlad fareee download shoe...</td>\n",
       "      <td>[\"my\", \"songarein\", \"so\", \"gareinlad\", \"fareee...</td>\n",
       "      <td>[\"songarein\", \"gareinlad\", \"fareee\", \"download...</td>\n",
       "      <td>[\"songarein\", \"gareinlad\", \"faree\", \"download\"...</td>\n",
       "      <td>[\"songarein\", \"gareinlad\", \"fareee\", \"download...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1          2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "4          5    0.0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory: left-right polarisation! #tru...   \n",
       "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  49158    NaN  happy, at work conference: right mindset leads...   \n",
       "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             clean_tweet  \\\n",
       "0      when fatheare is dysfyounctional and is so sel...   \n",
       "1      thanks foare lyft careedit cannot youse cayous...   \n",
       "2                                bihday yoyouare majesty   \n",
       "3      model love you take with you all the time in y...   \n",
       "4               factsgareinyouide society now motivation   \n",
       "...                                                  ...   \n",
       "49154  thoyougareinht factoarey left areigareinht pol...   \n",
       "49155  feelingarein like mearemaid haiareflip neveare...   \n",
       "49156  hillaarey campaigareinned today in ohio oh my ...   \n",
       "49157  happy at woarek confeareence areigareinht mind...   \n",
       "49158  my songarein so gareinlad fareee download shoe...   \n",
       "\n",
       "                                             tweet_token  \\\n",
       "0      [\"when\", \"fatheare\", \"is\", \"dysfyounctional\", ...   \n",
       "1      [\"thanks\", \"foare\", \"lyft\", \"careedit\", \"can\",...   \n",
       "2                      [\"bihday\", \"yoyouare\", \"majesty\"]   \n",
       "3      [\"model\", \"love\", \"you\", \"take\", \"with\", \"you\"...   \n",
       "4      [\"factsgareinyouide\", \"society\", \"now\", \"motiv...   \n",
       "...                                                  ...   \n",
       "49154  [\"thoyougareinht\", \"factoarey\", \"left\", \"areig...   \n",
       "49155  [\"feelingarein\", \"like\", \"mearemaid\", \"haiaref...   \n",
       "49156  [\"hillaarey\", \"campaigareinned\", \"today\", \"in\"...   \n",
       "49157  [\"happy\", \"at\", \"woarek\", \"confeareence\", \"are...   \n",
       "49158  [\"my\", \"songarein\", \"so\", \"gareinlad\", \"fareee...   \n",
       "\n",
       "                                    tweet_token_filtered  \\\n",
       "0      [\"fatheare\", \"dysfyounctional\", \"selfish\", \"da...   \n",
       "1      [\"thanks\", \"foare\", \"lyft\", \"careedit\", \"youse...   \n",
       "2                      [\"bihday\", \"yoyouare\", \"majesty\"]   \n",
       "3            [\"model\", \"love\", \"take\", \"time\", \"youare\"]   \n",
       "4         [\"factsgareinyouide\", \"society\", \"motivation\"]   \n",
       "...                                                  ...   \n",
       "49154  [\"thoyougareinht\", \"factoarey\", \"left\", \"areig...   \n",
       "49155  [\"feelingarein\", \"like\", \"mearemaid\", \"haiaref...   \n",
       "49156  [\"hillaarey\", \"campaigareinned\", \"today\", \"ohi...   \n",
       "49157  [\"happy\", \"woarek\", \"confeareence\", \"areigarei...   \n",
       "49158  [\"songarein\", \"gareinlad\", \"fareee\", \"download...   \n",
       "\n",
       "                                           tweet_stemmed  \\\n",
       "0      [\"fathear\", \"dysfyounct\", \"selfish\", \"dareagar...   \n",
       "1      [\"thank\", \"foar\", \"lyft\", \"careedit\", \"yous\", ...   \n",
       "2                       [\"bihday\", \"yoyouar\", \"majesti\"]   \n",
       "3             [\"model\", \"love\", \"take\", \"time\", \"youar\"]   \n",
       "4               [\"factsgareinyouid\", \"societi\", \"motiv\"]   \n",
       "...                                                  ...   \n",
       "49154  [\"thoyougareinht\", \"factoarey\", \"left\", \"areig...   \n",
       "49155  [\"feelingarein\", \"like\", \"mearemaid\", \"haiaref...   \n",
       "49156  [\"hillaarey\", \"campaigarein\", \"today\", \"ohio\",...   \n",
       "49157  [\"happi\", \"woarek\", \"confear\", \"areigareinht\",...   \n",
       "49158  [\"songarein\", \"gareinlad\", \"faree\", \"download\"...   \n",
       "\n",
       "                                        tweet_lemmatized  \n",
       "0      [\"fatheare\", \"dysfyounctional\", \"selfish\", \"da...  \n",
       "1      [\"thank\", \"foare\", \"lyft\", \"careedit\", \"youse\"...  \n",
       "2                      [\"bihday\", \"yoyouare\", \"majesty\"]  \n",
       "3            [\"model\", \"love\", \"take\", \"time\", \"youare\"]  \n",
       "4         [\"factsgareinyouide\", \"society\", \"motivation\"]  \n",
       "...                                                  ...  \n",
       "49154  [\"thoyougareinht\", \"factoarey\", \"leave\", \"arei...  \n",
       "49155  [\"feelingarein\", \"like\", \"mearemaid\", \"haiaref...  \n",
       "49156  [\"hillaarey\", \"campaigareinned\", \"today\", \"ohi...  \n",
       "49157  [\"happy\", \"woarek\", \"confeareence\", \"areigarei...  \n",
       "49158  [\"songarein\", \"gareinlad\", \"fareee\", \"download...  \n",
       "\n",
       "[49159 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "combine_df = pd.read_pickle(\"../lesson_1/result.pkl\")\n",
    "combine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4ea2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aare</th>\n",
       "      <th>aareareiv</th>\n",
       "      <th>aareoyound</th>\n",
       "      <th>abl</th>\n",
       "      <th>aboyout</th>\n",
       "      <th>absolyout</th>\n",
       "      <th>accept</th>\n",
       "      <th>accoyount</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>yoyouarear</th>\n",
       "      <th>yoyouareself</th>\n",
       "      <th>yoyoultyouare</th>\n",
       "      <th>yoyoungarein</th>\n",
       "      <th>yoyoup</th>\n",
       "      <th>yoyous</th>\n",
       "      <th>yoyoustomear</th>\n",
       "      <th>yoyout</th>\n",
       "      <th>yoyoutyoub</th>\n",
       "      <th>yyoummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aare  aareareiv  aareoyound  abl  aboyout  absolyout  accept  \\\n",
       "0         0          0           0    0        0          0       0   \n",
       "1         0          0           0    0        0          0       0   \n",
       "2         0          0           0    0        0          0       0   \n",
       "3         0          0           0    0        0          0       0   \n",
       "4         0          0           0    0        0          0       0   \n",
       "...     ...        ...         ...  ...      ...        ...     ...   \n",
       "49154     0          0           0    0        0          0       0   \n",
       "49155     0          0           0    0        0          0       0   \n",
       "49156     0          0           0    0        0          0       0   \n",
       "49157     0          0           0    0        0          0       0   \n",
       "49158     0          0           0    0        0          0       0   \n",
       "\n",
       "       accoyount  act  action  ...  yoyouarear  yoyouareself  yoyoultyouare  \\\n",
       "0              0    0       0  ...           0             0              0   \n",
       "1              0    0       0  ...           0             0              0   \n",
       "2              0    0       0  ...           0             0              0   \n",
       "3              0    0       0  ...           0             0              0   \n",
       "4              0    0       0  ...           0             0              0   \n",
       "...          ...  ...     ...  ...         ...           ...            ...   \n",
       "49154          0    0       0  ...           0             0              0   \n",
       "49155          0    0       0  ...           0             0              0   \n",
       "49156          0    0       0  ...           0             0              0   \n",
       "49157          0    0       0  ...           0             0              1   \n",
       "49158          0    0       0  ...           0             0              0   \n",
       "\n",
       "       yoyoungarein  yoyoup  yoyous  yoyoustomear  yoyout  yoyoutyoub  yyoummi  \n",
       "0                 0       0       0             0       0           0        0  \n",
       "1                 0       0       0             0       0           0        0  \n",
       "2                 0       0       0             0       0           0        0  \n",
       "3                 0       0       0             0       0           0        0  \n",
       "4                 0       0       0             0       0           0        0  \n",
       "...             ...     ...     ...           ...     ...         ...      ...  \n",
       "49154             0       0       0             0       0           0        0  \n",
       "49155             0       0       0             0       0           0        0  \n",
       "49156             0       0       0             0       0           0        0  \n",
       "49157             0       0       0             0       0           0        0  \n",
       "49158             0       0       0             0       0           0        0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english',\n",
    "                                   max_df=0.9,\n",
    "                                   max_features=1000)\n",
    "\n",
    "# Создаем the Bag-of-Words модель\n",
    "bag_of_words_stemmed = count_vectorizer.fit_transform(combine_df['tweet_stemmed'])\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names_stemmed = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words_stemmed.toarray(), columns = feature_names_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "714e5715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aareareived</th>\n",
       "      <th>aaree</th>\n",
       "      <th>aareoyound</th>\n",
       "      <th>able</th>\n",
       "      <th>aboyout</th>\n",
       "      <th>absolyoutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>accoyount</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>yoyoultyouaree</th>\n",
       "      <th>yoyoungarein</th>\n",
       "      <th>yoyoup</th>\n",
       "      <th>yoyous</th>\n",
       "      <th>yoyoustomeare</th>\n",
       "      <th>yoyoustomeares</th>\n",
       "      <th>yoyout</th>\n",
       "      <th>yoyoute</th>\n",
       "      <th>yoyoutyoube</th>\n",
       "      <th>yyoummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aareareived  aaree  aareoyound  able  aboyout  absolyoutely  accept  \\\n",
       "0                0      0           0     0        0             0       0   \n",
       "1                0      0           0     0        0             0       0   \n",
       "2                0      0           0     0        0             0       0   \n",
       "3                0      0           0     0        0             0       0   \n",
       "4                0      0           0     0        0             0       0   \n",
       "...            ...    ...         ...   ...      ...           ...     ...   \n",
       "49154            0      0           0     0        0             0       0   \n",
       "49155            0      0           0     0        0             0       0   \n",
       "49156            0      0           0     0        0             0       0   \n",
       "49157            0      0           0     0        0             0       0   \n",
       "49158            0      0           0     0        0             0       0   \n",
       "\n",
       "       accoyount  act  action  ...  yoyoultyouaree  yoyoungarein  yoyoup  \\\n",
       "0              0    0       0  ...               0             0       0   \n",
       "1              0    0       0  ...               0             0       0   \n",
       "2              0    0       0  ...               0             0       0   \n",
       "3              0    0       0  ...               0             0       0   \n",
       "4              0    0       0  ...               0             0       0   \n",
       "...          ...  ...     ...  ...             ...           ...     ...   \n",
       "49154          0    0       0  ...               0             0       0   \n",
       "49155          0    0       0  ...               0             0       0   \n",
       "49156          0    0       0  ...               0             0       0   \n",
       "49157          0    0       0  ...               1             0       0   \n",
       "49158          0    0       0  ...               0             0       0   \n",
       "\n",
       "       yoyous  yoyoustomeare  yoyoustomeares  yoyout  yoyoute  yoyoutyoube  \\\n",
       "0           0              0               0       0        0            0   \n",
       "1           0              0               0       0        0            0   \n",
       "2           0              0               0       0        0            0   \n",
       "3           0              0               0       0        0            0   \n",
       "4           0              0               0       0        0            0   \n",
       "...       ...            ...             ...     ...      ...          ...   \n",
       "49154       0              0               0       0        0            0   \n",
       "49155       0              0               0       0        0            0   \n",
       "49156       0              0               0       0        0            0   \n",
       "49157       0              0               0       0        0            0   \n",
       "49158       0              0               0       0        0            0   \n",
       "\n",
       "       yyoummy  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "49154        0  \n",
       "49155        0  \n",
       "49156        0  \n",
       "49157        0  \n",
       "49158        0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем the Bag-of-Words модель\n",
    "bag_of_words_lemmatized = count_vectorizer.fit_transform(combine_df['tweet_lemmatized'])\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names_lemmatized = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words_lemmatized.toarray(), columns = feature_names_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b1c71",
   "metadata": {},
   "source": [
    "2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.<br>\n",
    "●\tИгнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.<br>\n",
    "●\tОграничим количество слов, попадающий в мешок, с помощью max_features = 1000.<br>\n",
    "●\tИсключим стоп-слова с помощью stop_words='english'.<br>\n",
    "●\tОтобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15609bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                                   max_df=0.9,\n",
    "                                   max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d13f019c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aare</th>\n",
       "      <th>aareareiv</th>\n",
       "      <th>aareoyound</th>\n",
       "      <th>abl</th>\n",
       "      <th>aboyout</th>\n",
       "      <th>absolyout</th>\n",
       "      <th>accept</th>\n",
       "      <th>accoyount</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>yoyouarear</th>\n",
       "      <th>yoyouareself</th>\n",
       "      <th>yoyoultyouare</th>\n",
       "      <th>yoyoungarein</th>\n",
       "      <th>yoyoup</th>\n",
       "      <th>yoyous</th>\n",
       "      <th>yoyoustomear</th>\n",
       "      <th>yoyout</th>\n",
       "      <th>yoyoutyoub</th>\n",
       "      <th>yyoummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aare  aareareiv  aareoyound  abl  aboyout  absolyout  accept  \\\n",
       "0       0.0        0.0         0.0  0.0      0.0        0.0     0.0   \n",
       "1       0.0        0.0         0.0  0.0      0.0        0.0     0.0   \n",
       "2       0.0        0.0         0.0  0.0      0.0        0.0     0.0   \n",
       "3       0.0        0.0         0.0  0.0      0.0        0.0     0.0   \n",
       "4       0.0        0.0         0.0  0.0      0.0        0.0     0.0   \n",
       "...     ...        ...         ...  ...      ...        ...     ...   \n",
       "49154   0.0        0.0         0.0  0.0      0.0        0.0     0.0   \n",
       "49155   0.0        0.0         0.0  0.0      0.0        0.0     0.0   \n",
       "49156   0.0        0.0         0.0  0.0      0.0        0.0     0.0   \n",
       "49157   0.0        0.0         0.0  0.0      0.0        0.0     0.0   \n",
       "49158   0.0        0.0         0.0  0.0      0.0        0.0     0.0   \n",
       "\n",
       "       accoyount  act  action  ...  yoyouarear  yoyouareself  yoyoultyouare  \\\n",
       "0            0.0  0.0     0.0  ...         0.0           0.0       0.000000   \n",
       "1            0.0  0.0     0.0  ...         0.0           0.0       0.000000   \n",
       "2            0.0  0.0     0.0  ...         0.0           0.0       0.000000   \n",
       "3            0.0  0.0     0.0  ...         0.0           0.0       0.000000   \n",
       "4            0.0  0.0     0.0  ...         0.0           0.0       0.000000   \n",
       "...          ...  ...     ...  ...         ...           ...            ...   \n",
       "49154        0.0  0.0     0.0  ...         0.0           0.0       0.000000   \n",
       "49155        0.0  0.0     0.0  ...         0.0           0.0       0.000000   \n",
       "49156        0.0  0.0     0.0  ...         0.0           0.0       0.000000   \n",
       "49157        0.0  0.0     0.0  ...         0.0           0.0       0.279574   \n",
       "49158        0.0  0.0     0.0  ...         0.0           0.0       0.000000   \n",
       "\n",
       "       yoyoungarein  yoyoup  yoyous  yoyoustomear  yoyout  yoyoutyoub  yyoummi  \n",
       "0               0.0     0.0     0.0           0.0     0.0         0.0      0.0  \n",
       "1               0.0     0.0     0.0           0.0     0.0         0.0      0.0  \n",
       "2               0.0     0.0     0.0           0.0     0.0         0.0      0.0  \n",
       "3               0.0     0.0     0.0           0.0     0.0         0.0      0.0  \n",
       "4               0.0     0.0     0.0           0.0     0.0         0.0      0.0  \n",
       "...             ...     ...     ...           ...     ...         ...      ...  \n",
       "49154           0.0     0.0     0.0           0.0     0.0         0.0      0.0  \n",
       "49155           0.0     0.0     0.0           0.0     0.0         0.0      0.0  \n",
       "49156           0.0     0.0     0.0           0.0     0.0         0.0      0.0  \n",
       "49157           0.0     0.0     0.0           0.0     0.0         0.0      0.0  \n",
       "49158           0.0     0.0     0.0           0.0     0.0         0.0      0.0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем the Bag-of-Words модель\n",
    "bag_tfidf_stemmed = tfidf_vectorizer.fit_transform(combine_df['tweet_stemmed'])\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_tfidf_stemmed = tfidf_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_tfidf_stemmed.toarray(), columns = feature_tfidf_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "872f1e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aareareived</th>\n",
       "      <th>aaree</th>\n",
       "      <th>aareoyound</th>\n",
       "      <th>able</th>\n",
       "      <th>aboyout</th>\n",
       "      <th>absolyoutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>accoyount</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>yoyoultyouaree</th>\n",
       "      <th>yoyoungarein</th>\n",
       "      <th>yoyoup</th>\n",
       "      <th>yoyous</th>\n",
       "      <th>yoyoustomeare</th>\n",
       "      <th>yoyoustomeares</th>\n",
       "      <th>yoyout</th>\n",
       "      <th>yoyoute</th>\n",
       "      <th>yoyoutyoube</th>\n",
       "      <th>yyoummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aareareived  aaree  aareoyound  able  aboyout  absolyoutely  accept  \\\n",
       "0              0.0    0.0         0.0   0.0      0.0           0.0     0.0   \n",
       "1              0.0    0.0         0.0   0.0      0.0           0.0     0.0   \n",
       "2              0.0    0.0         0.0   0.0      0.0           0.0     0.0   \n",
       "3              0.0    0.0         0.0   0.0      0.0           0.0     0.0   \n",
       "4              0.0    0.0         0.0   0.0      0.0           0.0     0.0   \n",
       "...            ...    ...         ...   ...      ...           ...     ...   \n",
       "49154          0.0    0.0         0.0   0.0      0.0           0.0     0.0   \n",
       "49155          0.0    0.0         0.0   0.0      0.0           0.0     0.0   \n",
       "49156          0.0    0.0         0.0   0.0      0.0           0.0     0.0   \n",
       "49157          0.0    0.0         0.0   0.0      0.0           0.0     0.0   \n",
       "49158          0.0    0.0         0.0   0.0      0.0           0.0     0.0   \n",
       "\n",
       "       accoyount  act  action  ...  yoyoultyouaree  yoyoungarein  yoyoup  \\\n",
       "0            0.0  0.0     0.0  ...        0.000000           0.0     0.0   \n",
       "1            0.0  0.0     0.0  ...        0.000000           0.0     0.0   \n",
       "2            0.0  0.0     0.0  ...        0.000000           0.0     0.0   \n",
       "3            0.0  0.0     0.0  ...        0.000000           0.0     0.0   \n",
       "4            0.0  0.0     0.0  ...        0.000000           0.0     0.0   \n",
       "...          ...  ...     ...  ...             ...           ...     ...   \n",
       "49154        0.0  0.0     0.0  ...        0.000000           0.0     0.0   \n",
       "49155        0.0  0.0     0.0  ...        0.000000           0.0     0.0   \n",
       "49156        0.0  0.0     0.0  ...        0.000000           0.0     0.0   \n",
       "49157        0.0  0.0     0.0  ...        0.279635           0.0     0.0   \n",
       "49158        0.0  0.0     0.0  ...        0.000000           0.0     0.0   \n",
       "\n",
       "       yoyous  yoyoustomeare  yoyoustomeares  yoyout  yoyoute  yoyoutyoube  \\\n",
       "0         0.0            0.0             0.0     0.0      0.0          0.0   \n",
       "1         0.0            0.0             0.0     0.0      0.0          0.0   \n",
       "2         0.0            0.0             0.0     0.0      0.0          0.0   \n",
       "3         0.0            0.0             0.0     0.0      0.0          0.0   \n",
       "4         0.0            0.0             0.0     0.0      0.0          0.0   \n",
       "...       ...            ...             ...     ...      ...          ...   \n",
       "49154     0.0            0.0             0.0     0.0      0.0          0.0   \n",
       "49155     0.0            0.0             0.0     0.0      0.0          0.0   \n",
       "49156     0.0            0.0             0.0     0.0      0.0          0.0   \n",
       "49157     0.0            0.0             0.0     0.0      0.0          0.0   \n",
       "49158     0.0            0.0             0.0     0.0      0.0          0.0   \n",
       "\n",
       "       yyoummy  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "...        ...  \n",
       "49154      0.0  \n",
       "49155      0.0  \n",
       "49156      0.0  \n",
       "49157      0.0  \n",
       "49158      0.0  \n",
       "\n",
       "[49159 rows x 1000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем the Bag-of-Words модель\n",
    "bag_tfidf_lemmatized = tfidf_vectorizer.fit_transform(combine_df['tweet_lemmatized'])\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_tfidf_lemmatized = tfidf_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_tfidf_lemmatized.toarray(), columns = feature_tfidf_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e002c",
   "metadata": {},
   "source": [
    "3. Создайте мешок слов с помощью sklearn.feature_extraction.text.HashingVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.<br>\n",
    "Ограничим количество фичей, с помощью n_features = 1000.(можно изменить)<br>\n",
    "Исключим стоп-слова с помощью stop_words='english'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78bae66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "vectorizer = HashingVectorizer(n_features=1000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd78dde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49159, 1000)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "values_hash_stemmed = vectorizer.fit_transform(combine_df['tweet_stemmed'])\n",
    "print(values_hash_stemmed.shape)\n",
    "print(values_hash_stemmed.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05686594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49159, 1000)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "values_hash_lemmatized = vectorizer.fit_transform(combine_df['tweet_lemmatized'])\n",
    "print(values_hash_lemmatized.shape)\n",
    "print(values_hash_lemmatized.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53bc49d",
   "metadata": {},
   "source": [
    "4. Проверьте ваши векторайзеры на корпусе который использовали на вебинаре, составьте таблицу метод векторизации и скор который вы получили (в методах векторизации по изменяйте параметры что бы добиться лучшего скора) обратите внимание как падает/растёт скор при уменьшении количества фичей, и изменении параметров, так же попробуйте применить к векторайзерам PCA для сокращения размерности посмотрите на качество сделайте выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6e41b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label\n",
       "0  Stuning even for the non-gamer: This sound tra...  __label__2\n",
       "1  The best soundtrack ever to anything.: I'm rea...  __label__2\n",
       "2  Amazing!: This soundtrack is my favorite music...  __label__2\n",
       "3  Excellent Soundtrack: I truly like this soundt...  __label__2\n",
       "4  Remember, Pull Your Jaw Off The Floor After He...  __label__2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем данные\n",
    "data = open('corpus').read()\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split()\n",
    "    labels.append(content[0])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "# создаем df\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels\n",
    "trainDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2002c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c5e8a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b938ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rush\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
    "\n",
    "# labelEncode целевую переменную\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainDF['text'])\n",
    "\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)\n",
    "\n",
    "classifier = linear_model.LogisticRegression()\n",
    "classifier.fit(xtrain_count, train_y)\n",
    "predictions = classifier.predict(xvalid_count)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53c1752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_checker(max_features, max_df):\n",
    "    count_vectorizer = CountVectorizer(ngram_range=(1, 1), analyzer='word', stop_words='english',\n",
    "                                   max_df=max_df,\n",
    "                                   max_features=max_features)\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                                   max_df=max_df,\n",
    "                                   max_features=max_features)\n",
    "    hash_vectorizer = HashingVectorizer(n_features=max_features, stop_words='english')\n",
    "    vectorizers = [count_vectorizer, tfidf_vectorizer, hash_vectorizer]\n",
    "    score_list = []\n",
    "    for v in vectorizers:\n",
    "        v.fit(trainDF['text'])\n",
    "        xtrain_count =  v.transform(train_x)\n",
    "        xvalid_count =  v.transform(valid_x)\n",
    "\n",
    "        classifier = linear_model.LogisticRegression()\n",
    "        classifier.fit(xtrain_count, train_y)\n",
    "        predictions = classifier.predict(xvalid_count)\n",
    "        \n",
    "        score_list.append([v, accuracy_score(valid_y, predictions)])\n",
    "    return pd.DataFrame(score_list, columns = ['vectorizer', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "980c0b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>0.8228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>0.8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HashingVectorizer(n_features=1000, stop_words=...</td>\n",
       "      <td>0.7732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          vectorizer   score\n",
       "0  CountVectorizer(max_df=0.9, max_features=1000,...  0.8228\n",
       "1  TfidfVectorizer(max_df=0.9, max_features=1000,...  0.8408\n",
       "2  HashingVectorizer(n_features=1000, stop_words=...  0.7732"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_checker(max_features = 1000, max_df=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bb7de15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rush\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(max_df=0.9, max_features=6000,...</td>\n",
       "      <td>0.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer(max_df=0.9, max_features=6000,...</td>\n",
       "      <td>0.8628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HashingVectorizer(n_features=6000, stop_words=...</td>\n",
       "      <td>0.8408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          vectorizer   score\n",
       "0  CountVectorizer(max_df=0.9, max_features=6000,...  0.8496\n",
       "1  TfidfVectorizer(max_df=0.9, max_features=6000,...  0.8628\n",
       "2  HashingVectorizer(n_features=6000, stop_words=...  0.8408"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_checker(max_features = 6000, max_df=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f811a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(max_df=0.5, max_features=1000,...</td>\n",
       "      <td>0.8228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer(max_df=0.5, max_features=1000,...</td>\n",
       "      <td>0.8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HashingVectorizer(n_features=1000, stop_words=...</td>\n",
       "      <td>0.7732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          vectorizer   score\n",
       "0  CountVectorizer(max_df=0.5, max_features=1000,...  0.8228\n",
       "1  TfidfVectorizer(max_df=0.5, max_features=1000,...  0.8408\n",
       "2  HashingVectorizer(n_features=1000, stop_words=...  0.7732"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_checker(max_features = 1000, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c60ecda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rush\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(max_df=0.9, max_features=10000...</td>\n",
       "      <td>0.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer(max_df=0.9, max_features=10000...</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HashingVectorizer(n_features=10000, stop_words...</td>\n",
       "      <td>0.8396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          vectorizer   score\n",
       "0  CountVectorizer(max_df=0.9, max_features=10000...  0.8500\n",
       "1  TfidfVectorizer(max_df=0.9, max_features=10000...  0.8620\n",
       "2  HashingVectorizer(n_features=10000, stop_words...  0.8396"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_checker(max_features = 10000, max_df=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81f16cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(max_df=0.1, max_features=1000,...</td>\n",
       "      <td>0.8072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer(max_df=0.1, max_features=1000,...</td>\n",
       "      <td>0.8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HashingVectorizer(n_features=1000, stop_words=...</td>\n",
       "      <td>0.7732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          vectorizer   score\n",
       "0  CountVectorizer(max_df=0.1, max_features=1000,...  0.8072\n",
       "1  TfidfVectorizer(max_df=0.1, max_features=1000,...  0.8300\n",
       "2  HashingVectorizer(n_features=1000, stop_words=...  0.7732"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_checker(max_features = 1000, max_df=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab2648",
   "metadata": {},
   "source": [
    "С увеличением features, score растет. max_df меньше влияет на результат. Но все же с уменьшением скор незначительно падает."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
